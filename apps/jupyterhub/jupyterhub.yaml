apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: jupyterhub
  namespace: flux-system
spec:
  interval: 5m
  url: https://hub.jupyter.org/helm-chart/
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: jupyterhub
  namespace: flux-system
spec:
  interval: 5m
  releaseName: jupyterhub
  targetNamespace: jupyterhub
  chart:
    spec:
      chart: jupyterhub
      version: '4.0.0'
      sourceRef:
        kind: HelmRepository
        name: jupyterhub
        namespace: flux-system
  install:
    createNamespace: true
  valuesFrom:
    - kind: Secret
      name: jupyterhub-secret
      valuesKey: admin_password
      targetPath: hub.config.DummyAuthenticator.password
  values:
    hub:
      networkPolicy:
        enabled: true
        egress:
          - {}  # Allow all egress traffic
      config:
        JupyterHub:
          authenticator_class: 'jupyterhub.auth.DummyAuthenticator'
          admin_users:
            - admin
          allow_named_servers: true
          named_server_limit_per_user: 2
        KubeSpawner:
          profile_list:
            - display_name: "AMD64 - High Performance"
              description: "4GB RAM, 2 CPU cores - Best for data science & ML"
              default: true
              kubespawner_override:
                node_selector:
                  kubernetes.io/arch: amd64
                mem_limit: "4G"
                cpu_limit: 2.0
                mem_guarantee: "1G"
                cpu_guarantee: 0.5
            - display_name: "ARM64 - Power Efficient"
              description: "2GB RAM, 1 CPU core - Good for light analysis"
              kubespawner_override:
                node_selector:
                  kubernetes.io/arch: arm64
                mem_limit: "2G"
                cpu_limit: 1.0
                mem_guarantee: "512M"
                cpu_guarantee: 0.25
            - display_name: "GPU - NVIDIA RTX 3090"
              description: "24GB GPU RAM, 8GB System RAM - ML/AI workloads"
              kubespawner_override:
                node_selector:
                  nvidia.com/gpu: "true"
                mem_limit: "8G"
                cpu_limit: 4.0
                mem_guarantee: "2G"
                cpu_guarantee: 1.0
                image: jupyter/scipy-notebook:latest
                environment:
                  NVIDIA_VISIBLE_DEVICES: "all"
                  NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
                  LD_LIBRARY_PATH: "/usr/local/nvidia"
                volume_mounts:
                  - name: nvidia-libs
                    mount_path: /usr/local/nvidia
                    read_only: true
                  - name: nvidia-dev
                    mount_path: /dev
                volumes:
                  - name: nvidia-libs
                    host_path:
                      path: /usr/lib/wsl/lib
                  - name: nvidia-dev
                    host_path:
                      path: /dev
        c:
          JupyterHub:
            login_rate_limit: 5
            login_rate_limit_window: 300
          KubeSpawner:
            storage_pvc_ensure_timeout: 300
            http_timeout: 600
            start_timeout: 1200
            request_timeout: 600
            api_timeout: 600
            k8s_api_request_timeout: 600
            k8s_api_host: "https://kubernetes-api-lb.default.svc.cluster.local:6443"
      service:
        type: ClusterIP
      resources:
        requests:
          memory: 512Mi
          cpu: 250m
        limits:
          memory: 1Gi
          cpu: 500m
      nodeSelector:
        kubernetes.io/arch: arm64
    proxy:
      service:
        type: ClusterIP
      https:
        enabled: false
      chp:
        nodeSelector:
          kubernetes.io/arch: arm64
    singleuser:
      image:
        name: jupyter/scipy-notebook
        tag: 'latest'
      storage:
        capacity: 10Gi
        dynamic:
          storageClass: nfs-client-retain
          volumeNameTemplate: "volume-{username}"
      startTimeout: 600
    scheduling:
      userScheduler:
        enabled: false
    prePuller:
      hook:
        enabled: true
    cull:
      enabled: true
      timeout: 7200
      every: 900
      users: true
      removeNamedServers: true
